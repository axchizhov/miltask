{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from torch import nn\n",
    "from torchvision.datasets import CIFAR10\n",
    "from torchvision.transforms import ToTensor\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "\n",
    "from model import Autoencoder\n",
    "from utils import plot_reconstructed, grid_plot\n",
    "\n",
    "\n",
    "\n",
    "transform = ToTensor()\n",
    "\n",
    "data = CIFAR10('data/', train=False, download=True, transform=transform)\n",
    "# data = CIFAR10('data/', train=False, download=True)\n",
    "\n",
    "data_loader = torch.utils.data.DataLoader(dataset=data, batch_size=16, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "net = Autoencoder()\n",
    "criterion = nn.MSELoss()\n",
    "optimizer = torch.optim.Adam(net.parameters(), lr=1e-3)\n",
    "\n",
    "\n",
    "num_epochs = 100\n",
    "outputs = []\n",
    "tb = SummaryWriter()\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    for batch, _ in data_loader:\n",
    "        reconstructed = net(batch)\n",
    "        \n",
    "\n",
    "        loss = criterion(reconstructed, batch)\n",
    "        tb.add_scalar(\"Loss/train\", loss, epoch)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "    # Log results with a last batch from the loop\n",
    "    grid = grid_plot(batch, reconstructed)\n",
    "    tb.add_image('Original vs Reconstructed', grid, epoch)\n",
    "\n",
    "tb.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(image.shape)\n",
    "\n",
    "m = nn.Sequential(\n",
    "    nn.Conv2d(3, 16, kernel_size=3, stride=1, padding=1),\n",
    "    nn.LeakyReLU(),\n",
    "    nn.MaxPool2d(2, 2),\n",
    "    nn.Conv2d(16, 8, kernel_size=3, stride=2, padding=1),\n",
    "    nn.LeakyReLU(),\n",
    "    nn.MaxPool2d(2, 2),\n",
    "    nn.Flatten()\n",
    "    # nn.Linear(256, 128)\n",
    "    )\n",
    "\n",
    "m(image).shape"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "61fb6b4e7f5d2bd445f202524dd63e280d3bad4416a3373ef11e11887acaa28c"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
